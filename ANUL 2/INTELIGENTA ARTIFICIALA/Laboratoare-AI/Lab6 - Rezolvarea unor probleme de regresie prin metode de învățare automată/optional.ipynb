{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ce se întamplă în cazul clasificarii binare daca se modifică pragul de decizie din 0.5 în alte valori. Cum se poate aprecia calitatea clasificatorului pentru diferite valori ale pragului?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raspuns: Daca pragul este mai mare (de exemplu 0.8) atunci sansele ca algoritmul sa prezica corect label-ul pozitiv sunt mai mici. Aceasta situatie poate conduce de exemplu la clasificarea unor pacienti bolnavi ca fiind sanatosi, ceea ce nu este de dorit. Daca pragul este mai mic, sansele ca cei bolnavi sa fie clasificati corect sunt mai mari. (nu este atat de grav daca pacientii sanatosi sunt considerati bolnavi) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificationPerformance(ground_truth, computed_values):\n",
    "    \"\"\"\n",
    "    Returneaza TN (True Negative), FP(False Positive), FN(False Negative), TP(True Positive)\n",
    "    \"\"\"\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    TP = 0\n",
    "    \n",
    "    for i in range(0, len(ground_truth)):\n",
    "        #consideram malign = positive, benign = negative \n",
    "        if ground_truth[i] == \"M\":\n",
    "            if computed_values[i] == \"M\":\n",
    "                TP += 1\n",
    "            else:\n",
    "                FP += 1\n",
    "        else:\n",
    "            if computed_values[i] == \"B\":\n",
    "                TN += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "    return TN, FP, FN, TP\n",
    "\n",
    "\n",
    "def getAccuracy(TN, FP, FN, TP):\n",
    "    \"\"\" \n",
    "    accuracy represents the overall performance of classification model:\n",
    "    (TP+TN)/(TN+FP+FN+TP)\n",
    "    \"\"\"\n",
    "    return (TP+TN)/(TN+FP+FN+TP)\n",
    "\n",
    "def getPrecision(FP, TP):\n",
    "    \"\"\"\n",
    "    precision indicates how accurate the positive predictions are \n",
    "    TP/(TP+FP)\n",
    "    \"\"\"\n",
    "    return TP/(TP+FP)\n",
    "\n",
    "def getRecall(TP, FN):\n",
    "    \"\"\" \n",
    "    recall indicates the coverage of actual positive sample\n",
    "    TP/(TP+FN)\n",
    "    \"\"\"\n",
    "    return TP/(TP+FN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "from sklearn import linear_model\n",
    "import pandas as pd \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "from scipy.special import expit\n",
    "  \n",
    "# fetch dataset \n",
    "breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "def readData():\n",
    "    X = breast_cancer_wisconsin_diagnostic.data.features \n",
    "    y = breast_cancer_wisconsin_diagnostic.data.targets \n",
    "    data = {\n",
    "        \"radius\": preprocessing.normalize([X[\"radius1\"]])[0],\n",
    "        \"texture\": preprocessing.normalize([X[\"texture1\"]])[0],\n",
    "        \"diagnosis\": y[\"Diagnosis\"]\n",
    "    }\n",
    "    dataFrame = pd.DataFrame(data)\n",
    "    return dataFrame\n",
    "\n",
    "def plotDataDistribution(dataFrame):\n",
    "    fig, axes = plt.subplots(nrows=3, figsize=(15,15))\n",
    "    axes[0].hist(dataFrame[\"radius\"])\n",
    "    axes[0].set_title(\"Radius\")\n",
    "    axes[1].hist(dataFrame[\"texture\"])\n",
    "    axes[1].set_title(\"Texture\")\n",
    "    axes[2].hist(dataFrame[\"diagnosis\"])\n",
    "    axes[2].set_title(\"Diagnosis\")\n",
    "    plt.show()\n",
    "\n",
    "def plotData(dataFrame):\n",
    "    ind_malign = [i for i in range(0, dataFrame.shape[0]) if dataFrame[\"diagnosis\"].iloc[i] == 'M'] \n",
    "    ind_benign = [i for i in range(0, dataFrame.shape[0]) if dataFrame[\"diagnosis\"].iloc[i] == 'B']\n",
    "    radius_malign = [dataFrame[\"radius\"].iloc[i] for i in ind_malign]\n",
    "    radius_benign = [dataFrame[\"radius\"].iloc[i] for i in ind_benign]\n",
    "\n",
    "    texture_malign = [dataFrame[\"texture\"].iloc[i] for i in ind_malign]\n",
    "    texture_benign = [dataFrame[\"texture\"].iloc[i] for i in ind_benign]\n",
    "\n",
    "    fig, axes = plt.subplots()\n",
    "    axes.plot(radius_malign, texture_malign, 'ro')\n",
    "    axes.plot(radius_benign, texture_benign, 'go')\n",
    "    \n",
    "    axes.set_xlabel('Radius')\n",
    "    axes.set_ylabel('Texture')\n",
    "    axes.set_title('Relation between Radius and Texture')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def getTrainingAndValidationSets(dataFrame):\n",
    "    dataSize = dataFrame.shape[0]\n",
    "    \n",
    "    trainingIndexSet = np.random.choice(range(dataSize), size=int(0.8 * dataSize), replace=False)\n",
    "    validationIndexSet = [i for i in range(dataSize) if i not in trainingIndexSet]\n",
    "\n",
    "    trainingInputSet = [[dataFrame[\"radius\"].iloc[index], dataFrame[\"texture\"].iloc[index]] for index in trainingIndexSet]\n",
    "    trainingOutputSet = [dataFrame[\"diagnosis\"].iloc[index] for index in trainingIndexSet]\n",
    "\n",
    "    validationInputSet = [[dataFrame[\"radius\"].iloc[index], dataFrame[\"texture\"].iloc[index]] for index in validationIndexSet]\n",
    "    validationOutputSet = [dataFrame[\"diagnosis\"].iloc[index] for index in validationIndexSet]\n",
    "\n",
    "    return trainingInputSet, trainingOutputSet, validationInputSet, validationOutputSet\n",
    "\n",
    "\n",
    "def plotTrainingAndValidationSets(dataFrame):\n",
    "    trainingInputSet, trainingOutputSet, validationInputSet, validationOutputSet = getTrainingAndValidationSets(dataFrame)\n",
    "    ind_malign_test = [i for i in range(0, len(trainingInputSet)) if trainingOutputSet[i] == 'M'] \n",
    "    ind_benign_test = [i for i in range(0, len(trainingInputSet)) if trainingOutputSet[i] == 'B']\n",
    "\n",
    "    ind_malign_antrenament = [i for i in range(0, len(validationInputSet)) if validationOutputSet[i] == 'M'] \n",
    "    ind_benign_antrenament = [i for i in range(0, len(validationInputSet)) if validationOutputSet[i] == 'B'] \n",
    "\n",
    "    radius_malign_test = [trainingInputSet[i][0] for i in ind_malign_test]\n",
    "    radius_benign_test = [trainingInputSet[i][0] for i in ind_benign_test]\n",
    "\n",
    "    radius_malign_antrenament = [validationInputSet[i][0] for i in ind_malign_antrenament]\n",
    "    radius_benign_antrenament = [validationInputSet[i][0] for i in ind_benign_antrenament]\n",
    "\n",
    "    texture_malign_test = [trainingInputSet[i][1] for i in ind_malign_test]\n",
    "    texture_benign_test = [trainingInputSet[i][1] for i in ind_benign_test]\n",
    "\n",
    "    texture_malign_antrenament = [validationInputSet[i][1] for i in ind_malign_antrenament]\n",
    "    texture_benign_antrenament = [validationInputSet[i][1] for i in ind_benign_antrenament]\n",
    "\n",
    "    fig, axes = plt.subplots()\n",
    "    axes.plot(radius_malign_test, texture_malign_test, 'ro')\n",
    "    axes.plot(radius_benign_test, texture_benign_test, 'go')\n",
    "    axes.plot(radius_malign_antrenament, texture_malign_antrenament, 'r^')\n",
    "    axes.plot(radius_benign_antrenament, texture_benign_antrenament, 'g^')\n",
    "    \n",
    "    axes.set_xlabel('Radius')\n",
    "    axes.set_ylabel('Texture')\n",
    "    axes.set_title('Relation between Radius and Texture')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def getRegressorFromLibrary(dataFrame):\n",
    "    trainingInputSet, trainingOutputSet, _, _ = getTrainingAndValidationSets(dataFrame)\n",
    "    X = [el for el in trainingInputSet]\n",
    "    regressor = linear_model.SGDClassifier();\n",
    "    regressor.fit(X, trainingOutputSet)\n",
    "    return regressor\n",
    "\n",
    "def getErrors(dataFrame):\n",
    "    _,_, validationInputSet, validationOutputSet = getTrainingAndValidationSets(dataFrame)\n",
    "    regressor = getRegressorFromLibrary(dataFrame)\n",
    "    computedValidationOutputs = regressor.predict(validationInputSet)\n",
    "\n",
    "    TN, FP, FN, TP = clasificationPerformance(validationOutputSet, computedValidationOutputs)\n",
    "    accuracy = getAccuracy(TN, FP, FN, TP)\n",
    "    precision = getPrecision(FP, TP)\n",
    "    recall = getRecall(TP, FN)\n",
    "    return accuracy, precision, recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRegressor:\n",
    "    def __init__(self) -> None:\n",
    "        self.coeficienti = []\n",
    "    \n",
    "    def computeValue(self, line):\n",
    "        number = 0\n",
    "        for i in range(0, len(line)):\n",
    "            number += line[i] * self.coeficienti[i]\n",
    "        return expit(number)\n",
    "    \n",
    "    def train(self, input, output, learning_rate=0.01, epochs=1000):\n",
    "        newInput = [[1] + line for line in input]\n",
    "        \n",
    "        for feature in range(0, len(newInput[-1])):\n",
    "            self.coeficienti.append(0.0)\n",
    "\n",
    "        for epoch in range(0, epochs):\n",
    "            error = [0 for i in range(0, len(newInput[-1]))]\n",
    "            for i in range(0, len(newInput)):\n",
    "                computedValue = self.computeValue(newInput[i])\n",
    "                if output[i] == \"M\":\n",
    "                    err = 1 - computedValue\n",
    "                else:\n",
    "                    err = 0 - computedValue\n",
    "\n",
    "                for j in range(0, len(newInput[-1])):\n",
    "                    error[j] += err * newInput[i][j]\n",
    "            \n",
    "            for coef_index in range(0,len(self.coeficienti)):\n",
    "                self.coeficienti[coef_index] = self.coeficienti[coef_index] - learning_rate * error[coef_index]/len(newInput)         \n",
    "\n",
    "    def predict1(self, input):\n",
    "        output = []\n",
    "        for line in input:\n",
    "            value = self.computeValue([1] + line)\n",
    "            label = None\n",
    "            if value > 0.5:\n",
    "                label = \"M\"\n",
    "            else:\n",
    "                label = \"B\"                \n",
    "            output.append(label)\n",
    "        return output\n",
    "    \n",
    "    def predict2(self, input):\n",
    "        output = []\n",
    "        for line in input:\n",
    "            value = self.computeValue([1] + line)\n",
    "            label = None\n",
    "            if value > 0.8:\n",
    "                label = \"M\"\n",
    "            else:\n",
    "                label = \"B\"                \n",
    "            output.append(label)\n",
    "        return output\n",
    "    \n",
    "\n",
    "def getMyRegressor(dataFrame):\n",
    "    trainingInputSet, trainingOutputSet, _, _ = getTrainingAndValidationSets(dataFrame)\n",
    "    X = [el for el in trainingInputSet]\n",
    "    regressor = MyRegressor()\n",
    "    regressor.train(X, trainingOutputSet)\n",
    "    return regressor\n",
    "\n",
    "def getErrors2(dataFrame):\n",
    "    _,_, validationInputSet, validationOutputSet = getTrainingAndValidationSets(dataFrame)\n",
    "    regressor = getMyRegressor(dataFrame)\n",
    "    computedValidationOutputs = regressor.predict1(validationInputSet)\n",
    "\n",
    "    TN, FP, FN, TP = clasificationPerformance(validationOutputSet, computedValidationOutputs)\n",
    "    accuracy = getAccuracy(TN, FP, FN, TP)\n",
    "    precision = getPrecision(FP, TP)\n",
    "    recall = getRecall(TP, FN)\n",
    "    return accuracy, precision, recall\n",
    "\n",
    "def getErrors22(dataFrame):\n",
    "    _,_, validationInputSet, validationOutputSet = getTrainingAndValidationSets(dataFrame)\n",
    "    regressor = getMyRegressor(dataFrame)\n",
    "    computedValidationOutputs = regressor.predict2(validationInputSet)\n",
    "\n",
    "    TN, FP, FN, TP = clasificationPerformance(validationOutputSet, computedValidationOutputs)\n",
    "    accuracy = getAccuracy(TN, FP, FN, TP)\n",
    "    precision = getPrecision(FP, TP)\n",
    "    recall = getRecall(TP, FN)\n",
    "    return accuracy, precision, recall\n",
    "\n",
    "def predictCancerUsingMyRegressor1(dataFrame, input):\n",
    "    regressor = getMyRegressor(dataFrame)\n",
    "    output = regressor.predict1(input)\n",
    "    return output\n",
    "\n",
    "def predictCancerUsingMyRegressor2(dataFrame, input):\n",
    "    regressor = getMyRegressor(dataFrame)\n",
    "    output = regressor.predict2(input)\n",
    "    return output\n",
    "\n",
    "def predictCancerUsingLibraryRegressor(dataFrame, input):\n",
    "    regressor = getRegressorFromLibrary(dataFrame)\n",
    "    output = regressor.predict(input)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.5:  ['M']\n",
      "Threshold 0.8:  ['M']\n"
     ]
    }
   ],
   "source": [
    "dataFrame = readData()\n",
    "input = [[18, 10]]\n",
    "myOutput = predictCancerUsingMyRegressor1(dataFrame,input)\n",
    "myOutput2 = predictCancerUsingMyRegressor2(dataFrame, input)\n",
    "libraryOutput = predictCancerUsingLibraryRegressor(dataFrame, input)\n",
    "print(\"Threshold 0.5: \", myOutput)\n",
    "print(\"Threshold 0.8: \", myOutput2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEARNED MODEL: f(x) =  3.554730954094316  +  0.10944370390955513  * x1  +  0.12862091702695408  * x2\n",
      "THRESHOLD 0.5\n",
      "Accuracy =  0.4298245614035088\n",
      "Precision =  1.0\n",
      "Recall =  0.4298245614035088\n",
      "THRESHOLD 0.8\n",
      "Accuracy =  0.39473684210526316\n",
      "Precision =  1.0\n",
      "Recall =  0.39473684210526316\n"
     ]
    }
   ],
   "source": [
    "regressor2 = getMyRegressor(dataFrame)\n",
    "w0, w1, w2 = regressor2.coeficienti[0], regressor2.coeficienti[1], regressor2.coeficienti[2]\n",
    "print(\"LEARNED MODEL: f(x) = \", w0, \" + \", w1, \" * x1\", \" + \", w2, \" * x2\")\n",
    "\n",
    "accuracy2, precision2, recall2 = getErrors2(dataFrame)\n",
    "print(\"THRESHOLD 0.5\")\n",
    "print(\"Accuracy = \", accuracy2)\n",
    "print(\"Precision = \", precision2)\n",
    "print(\"Recall = \", recall2)\n",
    "\n",
    "accuracy22, precision22, recall22 = getErrors22(dataFrame)\n",
    "print(\"THRESHOLD 0.8\")\n",
    "print(\"Accuracy = \", accuracy22)\n",
    "print(\"Precision = \", precision22)\n",
    "print(\"Recall = \", recall22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rezolvarea unei probleme de regresie/clasificare prin: folosirea validarii încrucișate (K-fold cross validation) - pb cu happiness dupa pib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "from sklearn import linear_model\n",
    "import pandas as pd \n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "#Ce îi poate face pe oameni fericiți? - dupa PIB\n",
    "def readData(dataPath: str):\n",
    "    df = pd.read_csv(dataPath, delimiter=',', header='infer')\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "#split data frame in k sets\n",
    "def splitDataInKSets(dataFrame, k):\n",
    "    size = dataFrame.shape[0]\n",
    "    arr = np.array_split(range(size),k) \n",
    "    input = [[dataFrame[\"Economy..GDP.per.Capita.\"].iloc[i] for i in index] for index in arr]\n",
    "    output = [[dataFrame[\"Happiness.Score\"].iloc[i] for i in index] for index in arr]\n",
    "    return input, output\n",
    "\n",
    "def getErrors(computed_output, validation_output):\n",
    "    computedError = mean_squared_error(validation_output, computed_output)\n",
    "    return computedError\n",
    "\n",
    "def trainRegressor(regressor, dataFrame, k):\n",
    "    errors = []\n",
    "    input, output = splitDataInKSets(dataFrame, k)\n",
    "    for i in range(0, k):\n",
    "        validationInputSet = input[i]\n",
    "        validationOutputSet = output[i]\n",
    "        trainingInputSet = []\n",
    "        trainingOutputSet = []\n",
    "        for j in range(0, k):\n",
    "            if j != i:\n",
    "                trainingInputSet += input[j]\n",
    "                trainingOutputSet += output[j]\n",
    "        regressor.partial_fit([[trainingInputSet[ind]] for ind in range(0, len(trainingInputSet))], trainingOutputSet)\n",
    "        computed_output = regressor.predict([[validationInputSet[ind]] for ind in range(0, len(validationInputSet))])\n",
    "        errors.append(getErrors(computed_output, validationOutputSet))\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.240350012252453, 2.29935450966073, 0.4673785604497108, 0.5256477901443344, 0.5536900002234595, 0.399878092935935]\n",
      "Overall error =  2.4143831609444377\n"
     ]
    }
   ],
   "source": [
    "dataFrame = readData(\"2017.csv\")\n",
    "regressor = linear_model.SGDRegressor()\n",
    "errors = trainRegressor(regressor, dataFrame, 6)\n",
    "print(errors)\n",
    "overallError = sum(errors) / len(errors)\n",
    "print(\"Overall error = \", overallError)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigarea diferitelor funcții de loss - pt pb 1 - PIB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Squared Error** \n",
    "\n",
    "- **Huber** \n",
    "   \n",
    "- **Epsilon Insensitive** \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss type:  squared_error  Error =  0.2979756476653449\n",
      "Loss type:  huber  Error =  -0.04272638685058938\n",
      "Loss type:  epsilon_insensitive  Error =  0.3118348914352309\n",
      "Loss type:  squared_epsilon_insensitive  Error =  0.3423477410307654\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def getTrainingAndValidationSets(dfWorldHappiness):\n",
    "    dataSize = dfWorldHappiness.shape[0]\n",
    "    \n",
    "    trainingIndexSet = np.random.choice(range(dataSize), size=int(0.8 * dataSize), replace=False)\n",
    "    validationIndexSet = [i for i in range(dataSize) if i not in trainingIndexSet]\n",
    "\n",
    "    trainingInputSet = [dfWorldHappiness[\"Economy..GDP.per.Capita.\"].iloc[index] for index in trainingIndexSet]\n",
    "    trainingOutputSet = [dfWorldHappiness[\"Happiness.Score\"].iloc[index] for index in trainingIndexSet]\n",
    "\n",
    "    validationInputSet = [dfWorldHappiness[\"Economy..GDP.per.Capita.\"].iloc[index] for index in validationIndexSet]\n",
    "    validationOutputSet = [dfWorldHappiness[\"Happiness.Score\"].iloc[index] for index in validationIndexSet]\n",
    "\n",
    "    return trainingInputSet, trainingOutputSet, validationInputSet, validationOutputSet\n",
    "\n",
    "def getRegressor(dataFrame, loss_type):\n",
    "    trainingInputSet, trainingOutputSet, _, _ = getTrainingAndValidationSets(dataFrame)\n",
    "    X = [[el] for el in trainingInputSet]\n",
    "    regressor = linear_model.SGDRegressor(loss=loss_type)\n",
    "    regressor.fit(X, trainingOutputSet)\n",
    "    return regressor\n",
    "\n",
    "def main():\n",
    "    dataFrame = readData(\"2017.csv\")\n",
    "    _,_,validationInput,validationOutput = getTrainingAndValidationSets(dataFrame)\n",
    "    for loss_type in linear_model.SGDRegressor().loss_functions:\n",
    "        regressor = getRegressor(dataFrame, loss_type)\n",
    "        computedOutput = regressor.predict([[validationInput[i]] for i in range(0, len(validationInput))]) \n",
    "        err = metrics.r2_score(validationOutput, computedOutput)\n",
    "        print(\"Loss type: \", loss_type, \" Error = \", err)\n",
    "\n",
    "main()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
